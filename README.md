# Autonomous_vehicle_image_segmentation
This research presents an efficient semantic segmentation approach for autonomous vehicles by leveraging pre-trained SegFormer-B3 embeddings as input to a U-Net-based decoder. Unlike traditional methods, the SegFormer-B3 model is used without fine-tuning, reducing computational costs while maintaining strong performance. The decoder is trained to generate semantic segmentations using these transformer-based embeddings. Evaluated on autonomous driving benchmarks, the method achieves competitive mIOU, F1-score, recall, and precision, demonstrating its effectiveness. The results highlight that combining transformer-based embeddings with a U-Net decoder offers an efficient and lightweight solution for real-time semantic segmentation in resource-constrained environments.
